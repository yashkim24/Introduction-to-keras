{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/keras-logo-small.jpg)\n",
    "## Keras: Deep Learning library for Theano and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Deep learning?\n",
    "\n",
    ">Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost. It is the key to voice control in consumer devices like phones, tablets, TVs, and hands-free speakers. Deep learning is getting lots of attention lately and for good reason. Itâ€™s achieving results that were not possible before.\n",
    "\n",
    ">In deep learning, a computer model learns to perform classification tasks directly from images, text, or sound. Deep learning models can achieve state-of-the-art accuracy, sometimes exceeding human-level performance. Models are trained by using a large set of labeled data and neural network architectures that contain many layers.\n",
    "\n",
    "                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 1.Keras As A Deeplearning Library \n",
    "   * __why keras?__\n",
    "   \n",
    ">###  2.Keras Working Pipeline \n",
    "   * __Definition__ \n",
    "   * __Compilation__ \n",
    "   * __Training__ \n",
    "   * __Prediction and Evaluation__\n",
    "   \n",
    ">### 3.Keras Modules\n",
    "   * __Some Useful Modules in Keras__\n",
    "   \n",
    ">### 4.Applications\n",
    "   * __Transfer learning/fine tuning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/keras-tensorflow-logo.jpg)\n",
    "## Keras Deep Learning library with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. \n",
    "\n",
    ">It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "ref: https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Keras?\n",
    "\n",
    ">Keras is an API designed for human beings, not machines. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.\n",
    "    \n",
    ">This makes Keras easy to learn and easy to use. As a Keras user, you are more productive, allowing you to try more ideas than your competition, faster -- which in turn helps you win machine learning competitions.\n",
    "    \n",
    ">This ease of use does not come at the cost of reduced flexibility: because Keras integrates with lower-level deep learning languages (in particular TensorFlow), it enables you to implement anything you could have built in the base language. In particular, as tf.keras, the Keras API integrates seamlessly with your TensorFlow workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/arxiv-mentions.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Working Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL Definition\n",
    "There are two types of models available in Keras: the Sequential model and the Model class used with functional API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The simplest model is defined in the Sequential class which is a linear stack of Layers. You can create a Sequential model and define all of the layers in the constructor, for example: \n",
    "       \n",
    "       from keras.models import Sequential\n",
    "       model = Sequential(...)\n",
    "\n",
    "A more useful idiom is to create a Sequential model and add your layers in the order of the computation you wish to perform, for example:       \n",
    "       \n",
    "       from keras.models import Sequential\n",
    "       model = Sequential()\n",
    "       model.add(...)\n",
    "       model.add(...)\n",
    "       model.add(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The Keras functional API provides a more flexible way for defining models.\n",
    "\n",
    "It specifically allows you to define multiple input or output models as well as models that share layers. More than that, it allows you to define ad hoc acyclic network graphs.\n",
    "\n",
    "Models are defined by creating instances of layers and connecting them directly to each other in pairs, then defining a Model that specifies the layers to act as the input and output to the model,For Example:\n",
    "\n",
    "                         inputs = Input(shape=(3,))\n",
    "                         x = Dense(50, activation='relu')(inputs)\n",
    "                         output = Dense(1, activation = 'sigmoid')(x)\n",
    "                         n_net = Model(inputs, output)\n",
    "                         n_net.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "                         n_net.fit(x=dat_train, y=y_classifier_train, epochs=10,\n",
    "                         verbose=1, validation_data=(dat_test, y_classifier_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Before training a model, you need to configure the learning process, which is done via the compile method. It receives three arguments:\n",
    "\n",
    ">* An optimizer. This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class. See: optimizers.\n",
    ">* A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function. See: losses.\n",
    ">* A list of metrics. For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "### For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "### For custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function.\n",
    "          \n",
    "          model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=5, shuffle=False,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    ".predict() generates output predictions based on the input you pass it (for example, the predicted characters in the MNIST example)\n",
    "            \n",
    "            predictions = model.predict(x_test)\n",
    "            \n",
    ".evaluate() computes the loss based on the input you pass it, along with any other metrics that you requested in the metrics param when you compiled your model (such as accuracy in the MNIST example)\n",
    "            \n",
    "            score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model\n",
    "\n",
    "****\n",
    "<img src=\"imgs/Feed-forward.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "**Recognize handwritten digits**\n",
    "<img src=\"imgs/Examples-from-the-MNIST-dataset.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The MNIST database ([link](http://yann.lecun.com/exdb/mnist)) has a database of handwritten digits. \n",
    "\n",
    "The training set has $60,000$ samples. \n",
    "\n",
    "The test set has $10,000$ samples.\n",
    "\n",
    "The digits are size-normalized and centered in a fixed-size image. \n",
    "\n",
    "The data page has description on how the data was collected. It also has reports the benchmark of various algorithms on the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "x_train shape: (10000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_train shape:', X_test.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a0852f5278>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a085159a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[50050].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(75,kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(50,kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(25,kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "# Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 1.4603 - acc: 0.4481 - val_loss: 0.6785 - val_acc: 0.8082\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.7856 - acc: 0.7375 - val_loss: 0.4366 - val_acc: 0.8857\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.5996 - acc: 0.8260 - val_loss: 0.3000 - val_acc: 0.9276\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.5035 - acc: 0.8656 - val_loss: 0.2550 - val_acc: 0.9363\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.4522 - acc: 0.8805 - val_loss: 0.2285 - val_acc: 0.9433\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.4170 - acc: 0.8913 - val_loss: 0.2194 - val_acc: 0.9452\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.3855 - acc: 0.8982 - val_loss: 0.2061 - val_acc: 0.9505\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.3632 - acc: 0.9030 - val_loss: 0.1897 - val_acc: 0.9532\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.3497 - acc: 0.9076 - val_loss: 0.1897 - val_acc: 0.9538\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.3321 - acc: 0.9128 - val_loss: 0.1860 - val_acc: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a08a2379e8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 91,410\n",
      "Trainable params: 91,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.18596392909139395\n",
      "Test accuracy: 0.955\n",
      "Model Error: 4.50%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Model Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## ImageDataGenerator\n",
    ">Deep networks need large amount of training data to achieve good performance. To build a powerful image classifier using very little training data, image augmentation is usually required to boost the performance of deep networks. Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc.\n",
    ">\n",
    "Data augmentation powerful and common tool for increasing the dataset size and model generalizability is data augmentation. In fact, every competition winning ConvNet employs the use of data augmentation. Essentially, data augmentation is the process of artificially increasing the size of your dataset via transformations.\n",
    "\n",
    ">Keras provides the ImageDataGenerator class that defines the configuration for image data preparation and augmentation. This includes capabilities such as:\n",
    "\n",
    ">   *  Sample-wise standardization.\n",
    ">   *  Feature-wise standardization.\n",
    ">   *  ZCA whitening.\n",
    ">   *  Random rotation, shifts, shear and flips.\n",
    ">   *  Dimension reordering.\n",
    ">   *  Save augmented images to disk.\n",
    "\n",
    ">For More Reference '''https://machinelearningmastery.com/image-augmentation-deep-learning-keras/'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "    keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/cat.jpeg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Augmentated Images* \n",
    "\n",
    "<img src=\"imgs/cat_augmentation.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/dog_augmentation.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Keras some builtin datasets.Such as \n",
    "* **CIFAR10 small image classification**\n",
    "* **IMDB Movie reviews sentiment classification**\n",
    "* **MNIST database of handwritten digits**\n",
    "* **Boston housing price regression dataset**\n",
    "* **Fashion-MNIST database of fashion articles**\n",
    "<img src=\"imgs/fashion.jpg\" width=\"30%\">\n",
    "                                             Fashion-MNIST database of fashion articles\n",
    "<img src=\"imgs/cifar-10.png\" width=\"30%\">\n",
    "                                                CIFAR10 small image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications\n",
    "Keras Applications are deep learning models that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.\n",
    "\n",
    "Weights are downloaded automatically when instantiating a model. They are stored at ~/.keras/models/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning/Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">What is Transfer Learning?\n",
    "\n",
    ">* Transfer learning, is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.\n",
    "\n",
    ">Why Transfer Learning?\n",
    "\n",
    ">* In practice a very few people train a Convolution network from scratch (random initialisation) because it is rare to get enough dataset. So, using pre-trained network weights as initialisations or a fixed feature extractor helps in solving most of the problems in hand.\n",
    ">* Very Deep Networks are expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.\n",
    "\n",
    ">It has become the norm, not the exception, for researchers and practitioners alike to use transfer learning and fine-tuning, that is, transferring the network weights trained on a previous task like ImageNet to a new task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/fine_tuning.png\" width=\"70%\">\n",
    "                                          \n",
    "                                        Taken from http://cs231n.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The figure above and the bullets below describe some general advice for when to choose which approach.\n",
    "\n",
    ">   *  Similar & small dataset: avoid overfitting by not fine-tuning the weights on a small dataset, and use extracted features from the highest levels of the ConvNet to leverage dataset similarity.\n",
    "  *   Different & small dataset: avoid overfitting by not fine-tuning the weights on a small dataset, and use extracted features from lower levels of the ConvNet which are more generalizable.\n",
    "  *   Similar & large dataset: with a large dataset we can fine-tune the weights with less of a chance to overfit the training data.\n",
    "  *   Different & large dataset: with a large dataset we again can fine-tune the weights with less of a chance to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/dog_transfer.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 445s 4us/step\n",
      "Downloading data from https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 1s 33us/step\n",
      "Predicted: [('n02389026', 'sorrel', 0.98982763), ('n02422106', 'hartebeest', 0.0071356916), ('n02087394', 'Rhodesian_ridgeback', 0.0005791643)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'imgs/horse.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
